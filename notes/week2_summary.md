# Week 2 学习总结：构建 LLM 应用

本周，我们将一个简单的“基于规则”的应用程序进化为了一个集成大语言模型的智能应用。以下是核心的学习心得：

### 1. 从规则引擎到 LLM 的思维转变

- **以前 (基于启发式规则)**: 我们的应用依赖于正则表达式 (`regex`) 和关键词匹配。这种方式速度快且结果确定，但非常脆弱。一旦用户的自然语言不符合我们预设的格式（例如：“能不能麻烦提醒一下 Bob 检查 PR？”），规则引擎就会失效。
- **现在 (基于 LLM)**: 通过集成 Ollama (Llama 3.1)，应用能够理解句子的**语义**。它不再只是看格式，而是能像人一样识别出“这是一个任务请求”，无论表达得多么委婉。这是“AI 原生”软件的核心价值。

### 2. 结构化输出：驯服 LLM 的关键

- **问题**: LLM 本质上是用来聊天的，它吐出的是自由文本，这对程序来说很难处理。
- **解决方案**: **结构化输出 (Structured Outputs)**。我们利用 `Pydantic` 定义了一个严格的 `ActionItemsResponse` 模型（Schema）。通过将这个 Schema 传给 `ollama.chat` 函数，我们强制 LLM 不再“废话”，而是返回一个干净、可预测的 JSON 对象（例如 `{"items": ["任务1", "任务2"]}`）。
- **核心观点**: 不要把 LLM 仅仅当成聊天机器人，要把它们看作是一个**返回结构化数据的函数**。

### 3. 如何测试“不可预测”的 AI

- **挑战**: LLM 的输出具有非确定性（Non-deterministic）。同样的输入，每次生成的措辞可能略有不同。传统的 `assert result == "预期字符串"` 测试方法会直接崩溃。
- **我们的策略 (混合战术)**:
    1.  **结构验证**: 无论内容是什么，首先确保它返回的数据形状是对的（比如必须是一个列表）。
    2.  **关键词命中 (Fuzzy Match)**: 我们不要求字面完全匹配，而是检查关键信息是否存在。例如输入“给 Bob 发邮件”，我们断言结果中包含 `"Bob"` 和 `"邮件"` 即可。
    3.  **边界检查**: 测试空输入或无关闲聊，确保模型不会“产生幻觉”编造任务。

### 4. 现代后端开发最佳实践 (FastAPI)

- **Schema 即契约**: 我们用强类型的 `Pydantic` 模型（如 `NoteCreate`, `NoteRead`）替换了原来“裸奔”的 `Dict[str, Any]`。这样做带来了三大好处：
    - **自动校验**: FastAPI 自动帮我们拦截非法数据。
    - **清晰文档**: 自动生成标准的 API 文档（Swagger UI）。
    - **开发体验**: IDE 能提供精准的代码补全和类型检查。
- **路由整洁**: API 路由层只负责处理 HTTP 请求（解析参数、调用服务、返回响应），复杂的业务逻辑和底层数据库操作应该被剥离出去。

这周的练习让我们迈出了从“传统软件开发”向“AI 赋能软件开发”转型的第一步：**逻辑不再仅仅是被编写出来的，而是可以被模型“理解”出来的。**
